---
title: "EU AI Act 2026: Ein pragmatischer Einstieg für Teams"
date: "2026-02-11"
excerpt: "Was zählt wirklich? Risikokategorien, Evidence-Slots, Audit-Trails – und wie du das als Engineering-Prozess aufsetzt."
tags: ["EU AI Act", "Governance", "Compliance"]
---

Der EU AI Act fühlt sich auf Papier nach „Regulierung“ an – in der Praxis ist es **eine Systemarchitektur-Frage**:

- Was ist das System?
- Wofür wird es genutzt?
- Welche Daten fließen rein/raus?
- Wer trägt Verantwortung, und wie wird das nachgewiesen?

## Risiko-Kategorien (realistisch gedacht)

Die Kategorien sind kein Quiz. Die Frage ist: **Wie wahrscheinlich ist es, dass dein System Menschen schadet oder Grundrechte verletzt?** In vielen Organisationen entsteht High-Risk nicht durch „bösartige KI“, sondern durch **falsche Einbettung** in kritische Prozesse.

## Evidence-Slots statt PowerPoint

Wenn du nur eine Sache machst: behandle Anforderungen wie Tests. Jede Anforderung bekommt:

- Status (compliant/partial/non_compliant)
- Evidenz-Links
- Verantwortliche
- Datum und Version

## Audit-Trail ist nicht optional

Audits scheitern selten an „fehlendem Willen“. Sie scheitern an **fehlender Nachvollziehbarkeit**. Ein Audit-Trail ist ein Zeitstrahl: wer hat wann was entschieden und warum?

Wenn du das als Datenmodell baust, wird Compliance plötzlich banal: Zustand statt Drama.
